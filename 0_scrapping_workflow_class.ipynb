{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab732251",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5585bfda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy html element with the selector,\n",
      "\"listings-wrapper xs-flex xs-flex-wrap xs-grid sm-grid-cols-2 lg-grid-cols-3 xl-grid-cols-4 xs-gap-2 sm-gap-3 xs-mx2- sm-mx0\"\n"
     ]
    }
   ],
   "source": [
    "selector = 'listings-wrapper xs-flex xs-flex-wrap xs-grid sm-grid-cols-2 lg-grid-cols-3 xl-grid-cols-4 xs-gap-2 sm-gap-3 xs-mx2- sm-mx0'\n",
    "\n",
    "print(f'Copy html element with the selector,')\n",
    "print(f'\"{selector}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2ff03787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final main df\n",
    "final_cols = ['app_num','street_num','street', 'city', 'prov', \n",
    "              'district', 'latitude', 'longitude', 'sold_date', \n",
    "              'dom', 'sold_price', 'listing_price', 'beds','baths', \n",
    "              'size', 'mls', 'brokerage', 'listing_date', 'full_address']\n",
    "\n",
    "main_df_path = 'main_data/main_results.csv'\n",
    "\n",
    "empty_main_df = pd.DataFrame(columns = final_cols)\n",
    "empty_main_df.to_csv(main_df_path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "columns = ['unit_num', 'street', 'city', 'prov', \n",
    "               'district', 'latitude', 'longitude', \n",
    "               'sold_date', 'dom', 'sold_price',\n",
    "               'listing_price', 'beds', 'baths', \n",
    "               'size', 'mls', 'brokerage']\n",
    "\n",
    "# duplicated df\n",
    "main_df_path = 'review_data/duplicated_df.csv'\n",
    "\n",
    "empty_main_df = pd.DataFrame(columns = columns)\n",
    "empty_main_df.to_csv(main_df_path,index=False)\n",
    "\n",
    "# temp data\n",
    "main_df_path = 'temp/0_temp_prop_data.csv'\n",
    "\n",
    "empty_main_df = pd.DataFrame(columns = columns)\n",
    "empty_main_df.to_csv(main_df_path,index=False)\n",
    "\n",
    "geo_columns = ['row_index', 'unit_num', 'street', 'city', 'prov', \n",
    "               'district', 'latitude', 'longitude', \n",
    "               'sold_date', 'dom', 'sold_price',\n",
    "               'listing_price', 'beds', 'baths', \n",
    "               'size', 'mls', 'brokerage']\n",
    "\n",
    "# check coordintes df\n",
    "main_df_path = 'review_data/check_coordinates.csv'\n",
    "\n",
    "empty_main_df = pd.DataFrame(columns = geo_columns)\n",
    "empty_main_df.to_csv(main_df_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3789fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "\n",
    "class extract_properties:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    columns = ['unit_num', 'street', 'city', 'prov', \n",
    "               'district', 'latitude', 'longitude', \n",
    "               'sold_date', 'dom', 'sold_price',\n",
    "               'listing_price', 'beds', 'baths', \n",
    "               'size', 'mls', 'brokerage']\n",
    "\n",
    "        \n",
    "    def to_dataframe(self, zolo_text, columns = columns):\n",
    "        zolo_prop = zolo_text.split(\"data-propertyid\")\n",
    "        \n",
    "        prop_data = pd.DataFrame(columns=columns)\n",
    "        \n",
    "        for prop in zolo_prop:\n",
    "            if \"MLS\" in prop:\n",
    "                row = {}\n",
    "                details = prop.split(\"&\")\n",
    "\n",
    "                unit_num = details[13].split(';')[1]\n",
    "\n",
    "                street = details[15].split(';')[1]\n",
    "\n",
    "                city = details[19].split(';')[1]\n",
    "\n",
    "                prov = details[23].split(';')[1]\n",
    "\n",
    "                district = details[35].split(';')[1]\n",
    "\n",
    "                #latitude\n",
    "                latitude = details[42].split('=')[1].split()[0][1:-1]\n",
    "\n",
    "\n",
    "                #longitude\n",
    "                longitude = details[44].split('=')[1].split()[0][1:-1]\n",
    "\n",
    "                # sold date\n",
    "                sold_date = details[51].split('â€¢')[1]\n",
    "\n",
    "                # days on market\n",
    "                dom = details[55].split('\"p1\">')[1]\n",
    "\n",
    "                # sold price\n",
    "                sold_price = details[63].split('$')[1]\n",
    "                \n",
    "                # listing price\n",
    "                listing_price = details[67].split('$')[1]\n",
    "\n",
    "                # num of beds\n",
    "                beds = details[75].split(';')[1]\n",
    "\n",
    "                # num of baths\n",
    "                baths = details[79].split(';')[1]\n",
    "\n",
    "                # size info may not be available, subsequent detail index will change\n",
    "                # check if size detail exists in listing, 600-699 sqft or 1500-2000 sqft\n",
    "                if ('99 sqft' in prop) or ('00 sqft' in prop):\n",
    "                    size = details[83].split(';')[1]\n",
    "                    mls = details[91].split(';')[1]\n",
    "                    brokerage = details[99].split(';')[1]\n",
    "\n",
    "                else:\n",
    "                    size = np.NaN\n",
    "                    mls = details[87].split(';')[1]\n",
    "                    brokerage = details[95].split(';')[1]\n",
    "\n",
    "\n",
    "                row = [unit_num, street, city, prov, district, latitude, longitude, \n",
    "                       sold_date, dom, sold_price, listing_price, beds, baths, size, mls, brokerage]\n",
    "\n",
    "                row = pd.DataFrame([row], columns = columns)\n",
    "\n",
    "                prop_data = pd.concat([prop_data, row])\n",
    "                \n",
    "        \n",
    "        # remove all unwanted spaces in each columns\n",
    "        def strip_string(value):\n",
    "            # Check if the value is NaN (None) and return it as is\n",
    "            if pd.isna(value):\n",
    "                return value\n",
    "            # Otherwise, apply the strip() method to remove leading and trailing whitespaces\n",
    "            return value.strip()\n",
    "        \n",
    "        prop_data = prop_data.applymap(strip_string)   \n",
    "\n",
    "        property_df = prop_data.reset_index(drop=True)\n",
    "        \n",
    "        print(\"Successfully converted to a dataframe\")\n",
    "        \n",
    "        return property_df\n",
    "    \n",
    "    def clean_beds(self, property_df):\n",
    "        # remove the bd suffixes\n",
    "        property_df['beds'] = property_df['beds'].apply(lambda x: x.split()[0])\n",
    "        print(\"Successfully extracted beds\")\n",
    "       \n",
    "    \n",
    "    def clean_baths(self, property_df):\n",
    "        # remove the ba suffixes\n",
    "        property_df['baths'] = property_df['baths'].apply(lambda x: x.split()[0])\n",
    "        print(\"Successfully extracted baths\")\n",
    "        \n",
    "    def clean_dom(self, property_df):\n",
    "        \n",
    "        empty_rows = None\n",
    "        \n",
    "        if '' in property_df['dom'].unique():\n",
    "            empty_rows_index = property_df[property_df['dom']==''].index\n",
    "            print(f'Check rows on website with empty DOMs is in fact 0: {empty_rows_index}')\n",
    "            \n",
    "            # replace empty rows with empty strings\n",
    "            raw_df['dom'] = raw_df['dom'].replace('', '0 days on market')\n",
    "\n",
    "        \n",
    "        try:\n",
    "            property_df['dom'] = property_df['dom'].apply(lambda x: x.split()[0])\n",
    "            property_df['dom'] = pd.to_numeric(property_df['dom'])\n",
    "            print(\"Successfully extracted DOMs with no concerns\")\n",
    "        \n",
    "        except:\n",
    "            print('DOMs has an unexpected value')\n",
    "            \n",
    "                \n",
    "    def clean_sold_date(self, property_df):\n",
    "        def get_sold_date(date, currentYear=2023):\n",
    "            months_list = ['Jan', 'Feb', 'Mar', 'Apr', 'May', \n",
    "                           'Jun', 'Jul', 'Aug', 'Sep', 'Oct']\n",
    "            month = date.split()[0]\n",
    "            month_num = months_list.index(month)\n",
    "\n",
    "            date_num = date.split()[1].split('th')[0]\n",
    "            return pd.to_datetime(f'{currentYear}-{month_num+1}-{date_num}')\n",
    "\n",
    "        property_df['sold_date'] = property_df['sold_date'].apply(lambda x: get_sold_date(x))\n",
    "        \n",
    "        print(\"Successfully extracted sold date\")\n",
    "\n",
    "    def clean_prices(self, property_df):\n",
    "        \n",
    "        \"\"\"\n",
    "        Remvoe the comma and change price column datatypes to numeric\n",
    "        \"\"\"\n",
    "        def remove_comma(x):\n",
    "            \"\"\"\n",
    "            Remove the comma in he prices\n",
    "            Input: '625,000'\n",
    "            Ouput: '625000'\n",
    "            \"\"\"\n",
    "            number = ''\n",
    "            for i in x.split(','):\n",
    "                number += i\n",
    "            return number\n",
    "        \n",
    "        property_df[['sold_price','listing_price']] = property_df[['sold_price','listing_price']].applymap(remove_comma)\n",
    "            \n",
    "        property_df[['sold_price','listing_price']] = property_df[['sold_price','listing_price']].applymap(pd.to_numeric)\n",
    "        \n",
    "        print(\"Successfully converted price data from string to numeric\")\n",
    "            \n",
    "    ## make function, add_price_Difference\n",
    "    def add_listing_date(self, property_df):\n",
    "        # get listing date\n",
    "        listing_date = property_df['sold_date'] - pd.to_timedelta(property_df['dom'],\n",
    "                                                                  unit='days')\n",
    "        # add to main dataset\n",
    "        property_df['listing_date'] = listing_date\n",
    "        print(\"Successfully calculated listing date\")\n",
    "        \n",
    "    def estimate_size(self, property_df):\n",
    "        # clean unit sizes\n",
    "        size_range = property_df['size'].apply( lambda x: x.split()[0] if type(x) == str else x)\n",
    "\n",
    "        # get average size of range\n",
    "        size = size_range.apply(lambda x: ( int(x.split('-')[0]) + int(x.split('-')[1]) ) // 2 if type(x) == str else x )\n",
    "\n",
    "        # round off size to end in 00.0, ie. 500\n",
    "        size = size.apply(lambda x: x + 1 if x%2 == 1 else x)\n",
    "        size = size.astype('Int64')\n",
    "\n",
    "        property_df['size'] = size\n",
    "        print(\"Successfully calculated size\")\n",
    "        \n",
    "    def add_street_num(self, property_df):\n",
    "        # get the street number\n",
    "        property_df['street_num'] = property_df['unit_num'].apply(lambda x: x.split('-')[-1])\n",
    "        print(\"Successfully extracted street number\")\n",
    "\n",
    "    def add_app_num(self, property_df):\n",
    "        # if has no apartment number give the appartment number -999\n",
    "        property_df['app_num'] = property_df['unit_num'].apply(lambda x: x.split('-')[0] if len(x.split('-'))>1 else -999)\n",
    "        print(\"Successfully extracted appartment number\")\n",
    "        \n",
    "    def add_full_address(self, property_df):\n",
    "        # get lat and long coordinates from full address\n",
    "        property_df['full_address'] = property_df[['street_num','street','city','prov']].apply(lambda row: ' '.join(row), axis=1)\n",
    "        print(\"Successfully extracted full address\")\n",
    "        \n",
    "    global temp_data_path\n",
    "    temp_data_path = 'temp/0_temp_prop_data.csv'\n",
    "    \n",
    "    def temp_data(self, property_df):\n",
    "        \"\"\"\n",
    "        Store the property data in a temporary folder\n",
    "        \n",
    "        Useful for addressing wrong coordinates and duplicates\n",
    "        \"\"\"\n",
    "        # save current df to temp\n",
    "        property_df.to_csv(temp_data_path, index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_coordinates(self, address):\n",
    "            \"\"\"\n",
    "            Helper function for function check_geo_coordinates to get latitude and longitude coordinates \n",
    "            from the library geopy.\n",
    "            Input the address and return the latitude and longitude.\n",
    "            \"\"\"\n",
    "            # Initialize a geocoder with the Nominatim service\n",
    "            geolocator = Nominatim(user_agent=\"forward_geocoder\")\n",
    "\n",
    "            # Use the geocoder to get the location details (longitude and latitude)\n",
    "            location = geolocator.geocode(address)\n",
    "\n",
    "            if location:\n",
    "                latitude = location.latitude\n",
    "                longitude = location.longitude\n",
    "                return latitude, longitude\n",
    "            \n",
    "        \n",
    "    def check_geo_coordinates(self, property_df):\n",
    "        \"\"\"\n",
    "        This function compares the zolo coordinates and geopy coorindates.\n",
    "        If the sets of coordinates differ by 0.1 degree in either direction, \n",
    "            then return those rows for further review.\n",
    "            \n",
    "        0.001 degree is approximately 0.111km = 111 meters\n",
    "        \"\"\"\n",
    "        \n",
    "        # call on another class function to get coorindates\n",
    "        geo_coords = pd.DataFrame(tuple(property_df['full_address'].apply(self.get_coordinates )), columns=['lat','long'])\n",
    "            \n",
    "        # update latitude and longitude data type\n",
    "        property_df[['latitude','longitude']] = property_df[['latitude','longitude']].apply(pd.to_numeric)\n",
    "\n",
    "        # compare the coordinates\n",
    "        coords_df =  pd.DataFrame(columns =['lat_diff', 'long_diff'])\n",
    "\n",
    "        coords_df['lat_diff'] = np.abs(property_df['latitude'] - geo_coords['lat'])\n",
    "        coords_df['long_diff'] = np.abs(property_df['longitude'] - geo_coords['long'])\n",
    "\n",
    "        # 0.01 diff in lat is 1.11km \n",
    "        rows_to_check = coords_df[(coords_df['lat_diff'] > 0.01) | (coords_df['long_diff'] > 0.01)].index\n",
    "        \n",
    "        # df of rows to check\n",
    "        check_geo_df = property_df.iloc[rows_to_check]\n",
    "        print(check_geo_df.iloc[0])\n",
    "        \n",
    "        check_geo_df = check_geo_df.reset_index()\n",
    "        print(check_geo_df.iloc[0])\n",
    "\n",
    "        check_geo_df = check_geo_df.rename(columns={'index':'row_index'})\n",
    "        \n",
    "        \n",
    "        # master df of geo issues\n",
    "        check_geo_df_path = 'review_data/check_coordinates.csv'\n",
    "        main_check_geo_df = pd.read_csv(check_geo_df_path)\n",
    "        \n",
    "        main_check_geo_df = self.concat_df(main_check_geo_df, check_geo_df)\n",
    "        \n",
    "        main_check_geo_df.to_csv(check_geo_df_path, index=False)\n",
    "        \n",
    "        print(\"Completed adding rows that needs to be checked for coordinate issues\")\n",
    "        \n",
    "        \n",
    "    # final columns\n",
    "    final_cols = ['app_num','street_num','street', 'city', 'prov', \n",
    "              'district', 'latitude', 'longitude', 'sold_date', \n",
    "              'dom', 'sold_price', 'listing_price', 'beds','baths', \n",
    "              'size', 'mls', 'brokerage', 'listing_date', 'full_address']\n",
    "    \n",
    "    main_df_path = 'main_data/main_results.csv'\n",
    "      \n",
    "    global main_df\n",
    "    main_df = pd.read_csv(main_df_path)\n",
    "    \n",
    "\n",
    "    def important_cols(self, df):\n",
    "        \"\"\"\n",
    "        df is the processed data and we want to reduce the columns to only the cleaned columns\n",
    "        \"\"\"\n",
    "        return df[final_cols]\n",
    "         \n",
    "    def check_duplicates(self, new_df):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            main_df: master df\n",
    "            new_df: newly created df\n",
    "            \n",
    "        Checks the full address and MLS number for duplicates.\n",
    "        If there are duplicates, store them if a different database for manual review.\n",
    "        \"\"\"\n",
    "        \n",
    "        temp_df = pd.read_csv(temp_data_path)\n",
    "        \n",
    "        temp_new_df = self.concat_df(temp_df, new_df)\n",
    "        # get rows that are duplicates\n",
    "        duplicated_df = temp_new_df[temp_new_df.duplicated()]\n",
    "        \n",
    "        print(f\"Duplicate df shape is {duplicated_df.shape}\")\n",
    "        \n",
    "        dup_df_path = 'review_data/duplicated_df.csv'\n",
    "            \n",
    "        dup_df = pd.read_csv(dup_df_path)\n",
    "        \n",
    "        # add new rows to main dup df\n",
    "        dup_df = self.concat_df(dup_df, duplicated_df)\n",
    "        \n",
    "        # save \n",
    "        dup_df.to_csv(dup_df_path)\n",
    "        \n",
    "        print(\"Completed duplicate check\")\n",
    "            \n",
    "    \n",
    "    def concat_df(self, main_df,new_df):\n",
    "        \"\"\"\n",
    "        Input: main dataframe, newly processed dataframe\n",
    "        Returns: combined dataframe for a new main df\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.concat([main_df,new_df])\n",
    "    \n",
    "    def temp_to_main(self):\n",
    "        temp_data_path = 'temp/temp_prop_data.csv'\n",
    "        \n",
    "        temp_df = pd.read_csv(\"temp_data_path\")\n",
    "        \n",
    "        temp_df = self.important_cols(temp_df)\n",
    "        new_df = self.important_cols(new_df)\n",
    "            \n",
    "        concat_df(main_df, new_df).to_csv(main_df_path, index=False)\n",
    "        \n",
    "        print(\"Added new df to main\")\n",
    "        \n",
    "    def clear_rows(self,df):\n",
    "        \"\"\"\n",
    "        Clear rows but keep the same column structure.\n",
    "        \n",
    "        Used to clear\n",
    "            1. review geo coords table\n",
    "            2. review duplicates table\n",
    "            3. occasionally temp table\n",
    "        \"\"\"\n",
    "        \n",
    "        return df[0:0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2deb48",
   "metadata": {},
   "source": [
    "## Start workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "50c6b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = 'raw_data/zolo.html'\n",
    "\n",
    "with open(html_file, \"r\", encoding='utf-8') as f:\n",
    "    text= f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f337aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted to a dataframe\n",
      "Successfully extracted beds\n",
      "Successfully extracted baths\n",
      "Successfully extracted DOMs with no concerns\n",
      "Successfully extracted sold date\n",
      "Successfully converted price data from string to numeric\n",
      "Successfully calculated listing date\n",
      "Successfully calculated size\n",
      "Successfully extracted street number\n",
      "Successfully extracted appartment number\n",
      "Successfully extracted full address\n",
      "unit_num                                                    57-847\n",
      "street                                             Sheppard Avenue\n",
      "city                                                       Toronto\n",
      "prov                                                            ON\n",
      "district                                              Clanton Park\n",
      "latitude                                                       0.0\n",
      "longitude                                                      0.0\n",
      "sold_date                                      2023-07-28 00:00:00\n",
      "dom                                                             99\n",
      "sold_price                                                  870000\n",
      "listing_price                                               899900\n",
      "beds                                                             2\n",
      "baths                                                            2\n",
      "size                                                          1100\n",
      "mls                                                       C6039759\n",
      "brokerage        RE/MAX PRIME PROPERTIES - UNIQUE GROUP, BROKERAGE\n",
      "listing_date                                   2023-04-20 00:00:00\n",
      "street_num                                                     847\n",
      "app_num                                                         57\n",
      "full_address                        847 Sheppard Avenue Toronto ON\n",
      "Name: 1, dtype: object\n",
      "index                                                            1\n",
      "unit_num                                                    57-847\n",
      "street                                             Sheppard Avenue\n",
      "city                                                       Toronto\n",
      "prov                                                            ON\n",
      "district                                              Clanton Park\n",
      "latitude                                                       0.0\n",
      "longitude                                                      0.0\n",
      "sold_date                                      2023-07-28 00:00:00\n",
      "dom                                                             99\n",
      "sold_price                                                  870000\n",
      "listing_price                                               899900\n",
      "beds                                                             2\n",
      "baths                                                            2\n",
      "size                                                          1100\n",
      "mls                                                       C6039759\n",
      "brokerage        RE/MAX PRIME PROPERTIES - UNIQUE GROUP, BROKERAGE\n",
      "listing_date                                   2023-04-20 00:00:00\n",
      "street_num                                                     847\n",
      "app_num                                                         57\n",
      "full_address                        847 Sheppard Avenue Toronto ON\n",
      "Name: 0, dtype: object\n",
      "Completed adding rows that needs to be checked for coordinate issues\n",
      "Duplicate df shape is (0, 20)\n",
      "Completed duplicate check\n"
     ]
    }
   ],
   "source": [
    "apple = extract_properties()\n",
    "raw_df = apple.to_dataframe(text)\n",
    "apple.clean_beds(raw_df)\n",
    "apple.clean_baths(raw_df)\n",
    "apple.clean_dom(raw_df)\n",
    "apple.clean_sold_date(raw_df)\n",
    "apple.clean_prices(raw_df)\n",
    "apple.add_listing_date(raw_df)\n",
    "apple.estimate_size(raw_df)\n",
    "apple.add_street_num(raw_df)\n",
    "apple.add_app_num(raw_df)\n",
    "apple.add_full_address(raw_df)\n",
    "apple.temp_data(raw_df)\n",
    "\n",
    "# may require manual review because the street name is \n",
    "    # 1. does not match with an address in the geopy.geocoders database\n",
    "    # 2. Wrong\n",
    "        # 2.1 spelling error\n",
    "        # 2.2 missing information\n",
    "apple.check_geo_coordinates(raw_df)\n",
    "apple.check_duplicates(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc2c01a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the coordinates with the manually reviewed address\n",
    "# addreseses below are only for zolo.html file\n",
    "\n",
    "if html_file == 'raw_data/zolo.html':\n",
    "    correct_coords_1 = apple.get_coordinates('847 Sheppard Avenue W Toronto ON')\n",
    "    correct_coords_2 = apple.get_coordinates('66 Forest Manor Road Toronto ON')\n",
    "\n",
    "    raw_df.loc[1, ['latitude','longitude']]=correct_coords_1\n",
    "    raw_df.loc[1, ['latitude','longitude']]=correct_coords_2\n",
    "    raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5363a39d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['size'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6645ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "orange = extract_properties()\n",
    "temp_df = pd.read_csv(\"temp/temp_prop_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
